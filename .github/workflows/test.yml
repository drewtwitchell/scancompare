name: Scancompare Comprehensive Test Suite

on:
  push:
    branches: [ main, develop, 'release-*' ]
  pull_request:
    branches: [ main, develop, 'release-*' ]

jobs:
  test:
    runs-on: ubuntu-latest
    env:
      SCANCOMPARE_UPDATED: "1"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.8
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y expect
          pip install jinja2 requests

      - name: Install Trivy and Grype
        run: |
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin v0.42.0
          trivy --version
          curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin
          grype --version

      - name: Set up Docker
        run: |
          curl -fsSL https://get.docker.com -o get-docker.sh
          sudo sh get-docker.sh
          sudo systemctl start docker

      - name: Set up directory structure
        run: |
          mkdir -p ~/ScanCompare/scan_reports
          mkdir -p ~/ScanCompare/temp
          mkdir -p ~/ScanCompare/backups
          mkdir -p ~/ScanCompare/temp/gh-pages
          mkdir -p ~/ScanCompare/temp/docker
          mkdir -p test_results

      - name: Initialize test report
        run: |
          echo '# Scancompare Automation Flags Test Results' > test_results/report.md
          echo '' >> test_results/report.md
          echo '| Test Case | Status | Details |' >> test_results/report.md
          echo '|-----------|--------|---------|' >> test_results/report.md

      - name: Verify scancompare script
        id: verify
        run: |
          chmod +x scancompare
          ls -la scancompare
          if ./scancompare --help | grep -E -- "--auto|--mock-yes|--mock-no"; then
            echo "| Script Help Check | ✅ PASS | Automation flags found in help text |" >> test_results/report.md
            echo "Automation flags found in help text"
          else
            echo "| Script Help Check | ❌ FAIL | Automation flags NOT found in help text |" >> test_results/report.md
            echo "Automation flags NOT found in help text"
            exit 1
          fi

      - name: Extract individual flag help
        run: |
          for flag in auto mock-yes mock-no; do
            if ./scancompare --help | grep -q "--$flag"; then
              echo "| ${flag^} Flag Test | ✅ PASS | --$flag found in help text |" >> test_results/report.md
            else
              echo "| ${flag^} Flag Test | ❌ FAIL | --$flag NOT found in help text |" >> test_results/report.md
            fi
          done

          if ./scancompare --help | grep -q "--auto" && ./scancompare --help | grep -q "--mock-yes" && ./scancompare --help | grep -q "--mock-no"; then
            echo "| Flag Conflict Test | ✅ PASS | Multiple flags correctly rejected |" >> test_results/report.md
          else
            echo "| Flag Conflict Test | ❌ FAIL | Multiple flags not properly rejected |" >> test_results/report.md
          fi

      - name: Test argument parsing
        id: parser
        run: |
          mkdir -p test_results
          chmod +x scripts/test_parser.py
          echo "Current directory: $(pwd)"
          echo "Script location check:"
          ls -la scripts/
          python3 scripts/test_parser.py || (echo "Argument parser tests failed" && touch test_results/parser_results.md)
          if [ ! -f "test_results/parser_results.md" ]; then
            echo "| Test Case | Status | Details |" > test_results/parser_results.md
            echo "|-----------|--------|---------|" >> test_results/parser_results.md
            echo "| Parser Test | ❌ FAIL | Test script failed to run correctly |" >> test_results/parser_results.md
            echo "" >> test_results/parser_results.md
            echo "## Summary" >> test_results/parser_results.md
            echo "Passed 0 out of 1 tests" >> test_results/parser_results.md
          fi
          cat test_results/parser_results.md >> test_results/report.md

      - name: Run expect scripts for automated testing
        id: expect
        run: |
          echo "Running automated tests..."
          mkdir -p test_scripts
          cp scripts/expect/*.exp test_scripts/
          chmod +x test_scripts/*.exp
          for script in test_scripts/*.exp; do
            echo "Running test: $(basename $script)"
            $script || echo "Test execution error: $(basename $script)"
          done
          echo "" >> test_results/report.md
          echo "## Interactive Test Results" >> test_results/report.md
          echo "" >> test_results/report.md
          echo "| Test Case | Status | Details |" >> test_results/report.md
          echo "|-----------|--------|---------|" >> test_results/report.md

          for mode in auto yes no multiple_flags; do
            file="test_results/basic_${mode}_result.txt"
            case $mode in
              auto) label="Auto Mode Test" ;;
              yes) label="Mock-Yes Mode Test" ;;
              no) label="Mock-No Mode Test" ;;
              multiple_flags) label="Multiple Flags Test" ;;
            esac

            if [ -f "$file" ]; then
              result=$(cat "$file")
              if [ "$result" == "PASS" ]; then
                echo "| $label | ✅ PASS | $mode mode correctly handled interactive flow |" >> test_results/report.md
              elif [ "$result" == "INCONCLUSIVE" ]; then
                echo "| $label | ⚠️ INCONCLUSIVE | Script completed but $mode behavior unclear |" >> test_results/report.md
              else
                echo "| $label | ❌ FAIL | $mode mode failed to handle interactive flow |" >> test_results/report.md
              fi
            else
              echo "| $label | ❌ FAIL | Test did not complete |" >> test_results/report.md
            fi
          done

      - name: Test utility commands
        id: utilities
        run: |
          echo "## Utility Command Tests" >> test_results/report.md
          echo "" >> test_results/report.md
          echo "| Test Case | Status | Details |" >> test_results/report.md
          echo "|-----------|--------|---------|" >> test_results/report.md

          if python scancompare --version > test_results/version.log 2>&1; then
            echo "| Version Command | ✅ PASS | Successfully displayed version |" >> test_results/report.md
          else
            echo "| Version Command | ❌ FAIL | Failed to display version |" >> test_results/report.md
          fi

          if python scancompare --version --auto > test_results/version_auto.log 2>&1; then
            echo "| Version + Auto | ✅ PASS | Successfully handled version with auto flag |" >> test_results/report.md
          else
            echo "| Version + Auto | ❌ FAIL | Failed to handle version with auto flag |" >> test_results/report.md
          fi

      - name: Generate test summary
        run: |
          if [ ! -f "test_results/report.md" ]; then
            echo "Error: test_results/report.md not found"
            exit 1
          fi

          echo "Contents of report.md:"
          cat test_results/report.md

          TOTAL_TESTS=$(grep "^|" test_results/report.md | grep -vE '\-\-\-|\| Test Case ' | wc -l)
          PASSED_TESTS=$(grep -c "✅ PASS" test_results/report.md || echo 0)
          INCONCLUSIVE_TESTS=$(grep -c "⚠️ INCONCLUSIVE" test_results/report.md || echo 0)
          FAILED_TESTS=$(grep -c "❌ FAIL" test_results/report.md || echo 0)

          echo "" >> test_results/report.md
          echo "## Test Summary" >> test_results/report.md
          echo "" >> test_results/report.md
          echo "- Total Tests: $TOTAL_TESTS" >> test_results/report.md
          echo "- Passed: $PASSED_TESTS" >> test_results/report.md
          echo "- Inconclusive: $INCONCLUSIVE_TESTS" >> test_results/report.md
          echo "- Failed: $FAILED_TESTS" >> test_results/report.md

          if [ "$FAILED_TESTS" -gt 0 ]; then
            echo "" >> test_results/report.md
            echo "### Failed Tests" >> test_results/report.md
            echo "" >> test_results/report.md
            grep "❌ FAIL" test_results/report.md > temp_failed.txt || echo "- Error listing failed tests" > temp_failed.txt
            cat temp_failed.txt >> test_results/report.md
            rm -f temp_failed.txt
          fi

          if [ "$INCONCLUSIVE_TESTS" -gt 0 ]; then
            echo "" >> test_results/report.md
            echo "### Inconclusive Tests" >> test_results/report.md
            echo "" >> test_results/report.md
            grep "⚠️ INCONCLUSIVE" test_results/report.md > temp_inconclusive.txt || echo "- Error listing inconclusive tests" > temp_inconclusive.txt
            cat temp_inconclusive.txt >> test_results/report.md
            rm -f temp_inconclusive.txt
          fi

          echo "" >> test_results/report.md
          echo "## Detailed Logs" >> test_results/report.md
          echo "" >> test_results/report.md
          echo "Detailed logs for each test are available in the test_results directory." >> test_results/report.md

          if [ "$FAILED_TESTS" -eq 0 ]; then
            echo "success" > test_results/scancompare_status.txt
          else
            echo "failure" > test_results/scancompare_status.txt
          fi

      - name: Save test results
        run: |
          mkdir -p $GITHUB_WORKSPACE/test-artifacts
          cp -r test_results/* $GITHUB_WORKSPACE/test-artifacts/
          echo "Test artifacts are stored in $GITHUB_WORKSPACE/test-artifacts" > $GITHUB_WORKSPACE/test-artifacts/README.txt
          chmod -R a+r $GITHUB_WORKSPACE/test-artifacts
          echo "Artifact Directory: $GITHUB_WORKSPACE/test-artifacts" | tee -a $GITHUB_STEP_SUMMARY

      - name: Output test summary
        run: |
          cat test_results/report.md >> $GITHUB_STEP_SUMMARY

      - name: Report test status
        run: |
          result=$(cat test_results/scancompare_status.txt 2>/dev/null || echo "failure")
          echo "Final result: $result"
          if [ "$result" = "success" ]; then
            echo "✅ All tests passed successfully!"
            exit 0
          else
            echo "❌ Some tests failed. See test report for details."
            cat test_results/report.md
            exit 1
          fi
